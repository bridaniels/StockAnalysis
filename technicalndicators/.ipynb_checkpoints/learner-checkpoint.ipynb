{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae125aa3",
   "metadata": {},
   "source": [
    "# Machine Learning Model \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a85858b-5cf3-49bb-b49c-3491523029de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'fb'\n",
    "\n",
    "# Colors\n",
    "lightblue = '#4ac2fb'\n",
    "pinkyred = '#ff4e97'\n",
    "black='#333333'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb985299",
   "metadata": {},
   "source": [
    "### Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bef37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from importlib import reload\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "plt.rcParams['figure.dpi'] = 227\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b0ff79",
   "metadata": {},
   "source": [
    "### Import ARIMA, SARIMA Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4245007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas.plotting import autocorrelation_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ad594",
   "metadata": {},
   "source": [
    "### Import Tensorflow Keras Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f59b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.python.keras.optimizer_v2 import rmsprop\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Flatten, TimeDistributed, LSTM, Dense, Bidirectional, Dropout, ConvLSTM2D, Conv1D, GlobalMaxPooling1D, MaxPooling1D, Convolution1D, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from functools import partial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89eb1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(66)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b245aa",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('data/stocks')\n",
    "stocks = {}\n",
    "for file in files:\n",
    "    if file.split('.')[1] == 'csv':\n",
    "        name = file.split('.')[0]\n",
    "        stocks[name] = pd.read_csv('data/stocks/'+file, index_col='Date')\n",
    "        stocks[name].index = pd.to_datetime(stocks[name].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f68c2-60c7-4971-adb4-714a26cb1c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81d748e-eef0-4fe6-b6b2-3aa584eaa61c",
   "metadata": {},
   "source": [
    "---\n",
    "# Baseline Model\n",
    "- benchmark for comparing future more complex models\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014a3215-1141-4dbd-b0e3-232480784953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(stock):\n",
    "    \n",
    "    # turn into 0s and 1s\n",
    "    Binary = lambda data: [1 if x > 0 else 0 for x in data] \n",
    "    \n",
    "    # .randint(low,high,output size)\n",
    "    pred = np.random.randint(0,2,len(stock))\n",
    "    accuracy = accuracy_score(Binary(stock), pred)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e6d11-70b3-47c7-83a1-c46d20a8fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_accuracy = baseline_model(stocks[ticker.lower()].Return)\n",
    "print('Baseline Model Accuracy: {:.1f}%'.format(baseline_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41428438-98fc-41ca-bb12-9972ce981bce",
   "metadata": {},
   "source": [
    "### Accuracy Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2cb5ae-dee2-43e2-aa9c-55bc68e0da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_preds = []\n",
    "for i in range(1000):\n",
    "    baseline_preds.append(baseline_model(stocks[ticker.lower()].Return))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aea43c-3cee-4f28-b777-c7141c5d1616",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.hist(baseline_preds, bins=50, facecolor=lightblue)\n",
    "\n",
    "plt.title(f'Baseline Model Accuracy for {ticker}', fontsize=20)\n",
    "plt.axvline(np.array(baseline_preds).mean(), c='k', ls='--', lw=2)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95968eeb-d3ed-4e79-a578-d65ea95e7a29",
   "metadata": {},
   "source": [
    "---\n",
    "# [ARIMA](measurementsUsed/ARIMA.md)\n",
    "#### AutoRegressive Integrated Moving Averate\n",
    "- `p` = number of lags in the model\n",
    "- `d` = degree of differencing -> aka number of times raw observations are differenced\n",
    "- `q` = order of moving average -> moving average window size \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31672d7-a17d-49d3-873a-4a7cbe818aca",
   "metadata": {},
   "source": [
    "### Split Data for Training and Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3581656-cb4b-492f-ab84-8395bfec3d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entries = stocks[ticker.lower()].shape[0]\n",
    "last_252 = all_entries-253\n",
    "last_600 = all_entries-600\n",
    "test_600 = last_600-600\n",
    "train_600 = test_600-600\n",
    "print(f'{ticker.upper()} historical data contains {all_entries} entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8217ac7-d0fc-410a-87a8-920322f3f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = list(stocks[ticker.lower()]['Return'][test_600:last_600].values)\n",
    "train = list(stocks[ticker.lower()]['Return'][train_600:test_600].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66775b6-724e-4c8d-be73-f645b0a64021",
   "metadata": {},
   "source": [
    "### AutoCorrelation Function\n",
    "- how time series data points correlate to one another \n",
    "- ignore first value -> comparing itself to only itself "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e7d30-46b1-429c-8f5b-48d71cd511b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15,3)\n",
    "plot_acf(stocks[ticker.lower()].Return, lags=range(252))\n",
    "plt.title(f'Autocorrelation for {ticker.upper()} prices for first 252 trading days')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4077a458-d6f8-4b18-9539-7512515182f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15,3)\n",
    "plot_acf(stocks[ticker.lower()].Return, lags=range(last_252,all_entries))\n",
    "plt.title(f'Autocorrelation for {ticker.upper()} prices over last 252 trading days')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e2ee4-65f6-4166-a796-446c860d3b5e",
   "metadata": {},
   "source": [
    "#### Make Time Series 'Stationary' by Differencing \n",
    "- Differencing: subtract previous value from current value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b79b528-2815-42ab-bf8c-7903538b2993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA Orders\n",
    "# (p,d,q) -> (lag order, degree of differencing, order of moving average)\n",
    "orders = [(0,0,0), \n",
    "          (1,0,0),\n",
    "          (0,1,0),\n",
    "          (0,0,1),\n",
    "          (1,1,0)]\n",
    "\n",
    "Binary = lambda data: [1 if x > 0 else 0 for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b4aa9-a83e-463a-8021-4e5233ae818a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_predictions = {}\n",
    "accuracy_list = {}\n",
    "\n",
    "for order in orders:\n",
    "    try: \n",
    "        # shallow copy: new collection object and populating with references to child objects found in the original \n",
    "        # a reference of an object is copied in the other object\n",
    "        # changes do a copy DO REFLECT in the other object \n",
    "        history = train.copy() \n",
    "        order_predictions = []\n",
    "    \n",
    "        for i in range(len(test)):\n",
    "            model = ARIMA(history, order=order) #(observed time series, order=(p,d,q))\n",
    "            model_fit = model.fit(disp=0) #trains model using input training and data -> (disp=0) hides data\n",
    "            y_hat = model_fit.forecast() #predicited value of y (dependent variable) in regression equation  \n",
    "            order_predictions.append(y_hat[0][0]) #first element the prediction \n",
    "            history.append(test[i]) #adding following day's 'return' value to the model \n",
    "            print(f\"{ticker.upper()} prediction: {i+1} of {len(test)}\", end='\\r')\n",
    "    \n",
    "        # Binary = lambda data: [1 if x > 0 else 0 for x in data]\n",
    "        accuracy = accuracy_score(Binary(test),\n",
    "                                   Binary(order_predictions))\n",
    "        accuracy_list[order] = round(accuracy,3)*100\n",
    "        print('                       ', end='\\r')\n",
    "        print(f\"{order} - {round(accuracy,3)*100}% accuracy\", end='\\n')\n",
    "        all_predictions[order] = order_predictions\n",
    "    \n",
    "    except:\n",
    "        print(f\"{order} <== Wrong Order\", end='\\r')\n",
    "        pass  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a93383-2fa8-461b-afb7-0240b3f9200f",
   "metadata": {},
   "source": [
    "#### Review Predictions on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a188572-2002-4ec8-b254-08f71b4e2cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_list)\n",
    "# print(all_predictions)\n",
    "best_accuracy = max(accuracy_list.values())\n",
    "best_order = max(accuracy_list, key=accuracy_list.get)\n",
    "print(best_accuracy)\n",
    "print(best_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d8084b-b683-41ec-b2fc-af1cf89c66e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Plot\n",
    "fig = plt.figure(figsize=(18,5))\n",
    "plt.plot(test, label='Test', color=lightblue)\n",
    "plt.plot(all_predictions[best_order], label='Predictions', color=pinkyred)\n",
    "\n",
    "plt.legend(frameon=True, loc=1, ncol=1, fontsize=15, borderpad=.6)\n",
    "plt.title(f\"ARIMA Predictions for {ticker.upper()} given best predicted order {best_order}\")\n",
    "plt.xlabel('Days',fontsize=13)\n",
    "plt.ylabel('Returns',fontsize=13)\n",
    "\n",
    "# Arrow from Subplot to Main Plot\n",
    "plt.annotate('',\n",
    "            xy=(15,0.05),\n",
    "            xytext=(150,.2),\n",
    "            fontsize=10,\n",
    "            arrowprops={'width':0.4, 'headwidth':7,'color':black})\n",
    "\n",
    "# Small Subplot\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "rect = patches.Rectangle((0,-.05),30,.1, ls='--', lw=2, facecolor='y', edgecolor='k', alpha=.5)\n",
    "ax.add_patch(rect)\n",
    "\n",
    "plt.axes([.25,1,.2,.5])\n",
    "plt.plot(test[:30], color=lightblue)\n",
    "plt.plot(all_predictions[best_order][:30], color=pinkyred)\n",
    "\n",
    "plt.tick_params(axis='both', labelbottom=False, labelleft=False)\n",
    "plt.title('Lag')\n",
    "\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3652a2f4-5d46-44a4-bf74-972595ef016a",
   "metadata": {},
   "source": [
    "#### Histogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b280e5-a75e-4a5c-911b-26a8107e78ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29058386-4b6d-4621-b07f-0cb953f9f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.hist(stocks[ticker.lower()][test_600:last_600].reset_index().Return, \n",
    "         bins=num_bins, label='True', facecolor=lightblue)\n",
    "plt.hist(all_predictions[best_order], \n",
    "         bins=num_bins, label='Predicted', color=pinkyred, alpha=.7)\n",
    "plt.axvline(0,c='k',ls='--')\n",
    "\n",
    "plt.title(f\"{ticker.upper()}: ARIMA True vs. Predicted Value Distribution for best predicted order {best_order}\")\n",
    "plt.legend(frameon=True,loc=1, ncol=1,fontsize=10,borderpad=.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540c1334-9a67-488f-a065-8834c3cd0b95",
   "metadata": {},
   "source": [
    "#### Interpret via Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528df834-023c-4919-9b74-17ed56a201e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Binary = lambda data: [1 if x > 0 else 0 for x in data]\n",
    "\n",
    "test_binary = Binary(stocks[ticker.lower()][test_600:last_600].reset_index().Return)\n",
    "train_binary = Binary(all_predictions[best_order])\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(test_binary, train_binary).ravel()\n",
    "accuracy = accuracy_score(test_binary, train_binary)\n",
    "\n",
    "print(f\"True Positive and Negative: {tp + tn}\")\n",
    "print(f\"False Positive and Negative: {fp + fn}\")\n",
    "print(f\"Accuracy: {round(accuracy*100, 5)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3890d3b9-af59-482e-a45f-71424e16370b",
   "metadata": {},
   "source": [
    "---\n",
    "# Features Selection via [XGBoost](measurementsUsed/xgboost.md)\n",
    "- extract features for neural networks to improve model accuracy and boost training \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e3a563-b102-4a0d-85a3-43f2f6a2773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(dataframe, scale=(0,1)):\n",
    "    # Scale Features to [0-1]\n",
    "    columns = dataframe.columns \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.feature_range = scale \n",
    "    return pd.DataFrame(scaler.fit_transform(dataframe), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b371e79-15eb-4c77-b1c7-363c95de56dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_ticker = scale(stocks[ticker.lower()], scale=(0,1))\n",
    "# print(scaled_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafb0eb2-fca1-4c8b-9bd0-b58652843504",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled_ticker[:-1]\n",
    "y = stocks[ticker.lower()].Return.shift(-1)[:-1]\n",
    "# print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f3dda6-ffee-4310-9fdb-70b0a0930fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X[1500:],y[1500:], eval_metric='merror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863ad3f-569e-4b09-aff9-c1f00b196c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = pd.DataFrame({ 'Feature': X.columns,\n",
    "                                  'Importance': xgb.feature_importances_}) \\\n",
    "                                .sort_values('Importance', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9ce5e7-e38f-4879-a440-5e7b820749cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.barh(important_features.Feature, important_features.Importance, color=lightblue)\n",
    "\n",
    "plt.title(f\"XGBoost - Feature Importance - {ticker.upper()}\", fontsize=20)\n",
    "plt.xlabel('Importance', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ac3c65-e3aa-4578-ab23-7ab5dcf56a11",
   "metadata": {},
   "source": [
    "---\n",
    "# Deep Neural Networks\n",
    "---\n",
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ace0e6-4b70-4716-89ab-b04377842219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.python.keras.optimizer_v2 import rmsprop\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, TimeDistributed, Bidirectional, Dropout, ConvLSTM2D, Conv1D, GlobalMaxPooling1D, MaxPooling1D, Convolution1D, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Tensorflow Keras Libraries Used\n",
    "# LSTM Network \n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from functools import partial "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e69580-d526-4294-a2d7-3d101babc2b2",
   "metadata": {},
   "source": [
    "#### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c823ca-846e-45a6-a965-77e792e809a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 21\n",
    "\n",
    "scaled_ticker = scale(stocks[ticker.lower()], scale=(0,1))\n",
    "# print(scaled_ticker)\n",
    "scaled_ticker.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae990413-6706-40b9-86fa-d024e1139097",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_ticker.dropna(inplace=True)\n",
    "\n",
    "print('No Missing Data') if sum(scaled_ticker.isna().sum())==0 else scaled_ticker.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f9b25-caf5-4b43-912b-09961591abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_multivariate(features, target, n_steps, split=True, ratio=0.8):\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(len(features)):\n",
    "        end_index = i + n_steps\n",
    "        if end_index > len(features):\n",
    "            break\n",
    "        seq_x, seq_y = features[i:end_index], target[end_index-1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    if split == True:\n",
    "        X_train = np.array(X[:round(len(X)*ratio)])\n",
    "        y_train = np.array(y[:round(len(X)*ratio)])\n",
    "        X_test = np.array(X[round(len(X)*ratio):])\n",
    "        y_test = np.array(y[round(len(X)*ratio):])\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "    else:\n",
    "        return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba9cd4b-7bd9-4755-bc2f-70d8844427e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, \\\n",
    "y_train, \\\n",
    "X_test, \\\n",
    "y_test = split_multivariate(scaled_ticker.to_numpy()[:-1],\n",
    "                         stocks[ticker.lower()].Return.shift(-1).to_numpy()[:-1],\n",
    "                         n_steps,\n",
    "                         split=True,\n",
    "                         ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed92a0-2210-4b2c-8635-60737951ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb37008-b64d-44e3-93bf-8ad56eaa942a",
   "metadata": {},
   "source": [
    "# LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d320ccb7-4a12-4cf3-9fd8-424714c19038",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "n_steps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]\n",
    "\n",
    "print(f\"Steps: {n_steps}\")\n",
    "print(f\"Features: {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5f992f-6af1-4840-b4d8-b5f90c06e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name=\"LSTM_Network_Sequential_Model\")\n",
    "\n",
    "# can pass `Input()` to predefine the shape of the model in it's own line\n",
    "# model.add(Input(shape=(n_steps,n_features)))\n",
    "# model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "\n",
    "# or you can pass it into the first layer \n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(50, activation='relu', return_sequences=False))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd259a-6b71-40d1-9986-2bd3b8f9c81c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Layer Weight and Biases \n",
    "num_layers = len(model.layers)\n",
    "\n",
    "layers_weights = {}\n",
    "layers_biases = {}\n",
    "for i in range(num_layers):\n",
    "    layers_weights[i] = model.layers[i].get_weights()[0]\n",
    "    layers_biases[i] = model.layers[i].get_weights()[1]\n",
    "\n",
    "print(f\"Layers of the Sequential Model: {num_layers}\")\n",
    "print(f\" Bias defined when layer is called to be added to model\")\n",
    "print(f\" Layer 1: (Weight: {len(layers_weights[0])}, Bias: {len(layers_biases[0])})\")\n",
    "print(f\" Layer 2: (Weight: {len(layers_weights[1])}, Bias: {len(layers_biases[1])})\")\n",
    "print(f\" Layer 3: (Weight: {len(layers_weights[2])}, Bias: {len(layers_biases[2])})\")\n",
    "print(f\" Layer 4: (Weight: {len(layers_weights[3])}, Bias: {len(layers_biases[3])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2413e0de-1898-4e26-89ad-e12fae442411",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed51e29f-662b-4f9e-b49e-cefd9b95efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=100, verbose=0, validation_data=[X_test, y_test], use_multiprocessing=True)\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(model.history.history['loss'], label='Loss')\n",
    "plt.plot(model.history.history['val_loss'], label='Value Loss')\n",
    "\n",
    "plt.legend(frameon=True, loc=1, borderpad=.6)\n",
    "plt.title(f\"LSTM - Training Process for {ticker.upper()}\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7550a47-1c3a-4615-829f-455eb36c39a0",
   "metadata": {},
   "source": [
    "##### LSTM Network: Daily Return Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf9c861-82d6-43f7-a45a-7fb30dc1e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLevaluation(X, y, model, n_preds=10, random=True, show_graph=True): \n",
    "    \n",
    "    n_steps = X.shape[1]\n",
    "    max_random_int = len(y) - n_steps \n",
    "    y_true, y_pred = [], []\n",
    "    prediction_accuracy, slices = [],[]\n",
    "    \n",
    "    for i in range(n_preds): \n",
    "        if random == True: \n",
    "            position = np.random.randint(0, max_random_int)\n",
    "        else: \n",
    "            position = i \n",
    "        \n",
    "        y_hat = model.predict(X[position:position+1])[0][0]\n",
    "        y_pred.append(y_hat)\n",
    "        y_true.append(y[position])\n",
    "        y_current = y[position]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # if correctly predics return c=0\n",
    "        # else: c= previous sequence position \n",
    "        if y.min() < 0: c = 0 \n",
    "        else: c = y[position-1]\n",
    "            \n",
    "        if ((y_hat > c) & (y_current > c)) or ((y_hat < c) & (y_current < c)): \n",
    "                acc = 1\n",
    "        else: \n",
    "            acc = 0 \n",
    "              \n",
    "            \n",
    "        prediction_accuracy.append(acc)\n",
    "        slices.append((list(y[position - n_steps:position + 1]), \n",
    "                      list(y[position - n_steps: position]) + [y_hat], \n",
    "                      acc))\n",
    "        \n",
    "        \n",
    "    if show_graph == True: \n",
    "        plt.rcParams['figure.dpi'] = 227\n",
    "        plt.style.use('seaborn-whitegrid')\n",
    "        plt.figure(figsize=(18,5))\n",
    "        \n",
    "        plt.bar(range(n_preds), y_true[:], width=.7, alpha=.6, color=lightblue, label=\"True\")\n",
    "        plt.bar(range(n_preds), y_pred[:], width=.7, alpha=.6, color=pinkyred, label=\"Predicted\")\n",
    "        plt.axhline(0, color=black, lw=.8)\n",
    "        \n",
    "        plt.legend(loc=1)\n",
    "        plt.title(f\"Daily Return Prediction for {ticker.upper()}\", fontsize=15)\n",
    "        plt.show()\n",
    "    \n",
    "    print(f\"MSE: {mean_squared_error(y_true, y_pred)}\")\n",
    "    print(f\"Accuracy: {round((sum(prediction_accuracy)/len(prediction_accuracy) * 100),2)}%\")\n",
    "    return slices, np.array(y_true), np.array(y_pred)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58666bf-306c-49cd-bb86-a318feb6f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one of these inputs is 'NAN'\n",
    "# no predicted \n",
    "pred, y_true, y_pred = MLevaluation(X_test, y_test, model, random=False, n_preds=50, show_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354672bd-8e1b-47fb-888b-eee8d8f1925e",
   "metadata": {},
   "source": [
    "# Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a30a0c-cc33-4c9d-b790-6ee502cc6727",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "n_steps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]\n",
    "\n",
    "model = Sequential() \n",
    "\n",
    "model.add(Conv1D(filters=20, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4353d3-a07e-4bf3-9697-2bca093923e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd1705-43d8-4d0e-9c4e-90169192c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=25, verbose=0, validation_data=[X_test, y_test], use_multiprocessing=True)\n",
    "\n",
    "plt.figure(figsize=(18,5))\n",
    "plt.plot(model.history.history['loss'], label='Loss')\n",
    "plt.plot(model.history.history['val_loss'], label='Value Loss')\n",
    "\n",
    "plt.legend(frameon=True, loc=1)\n",
    "plt.title('Convolutional Network: Training Process for '+ticker.upper())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def95325-89da-491e-aafd-5048a8d9c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(X, y, model, n_preds=10, random=True, show_graph=True):\n",
    "    \n",
    "    n_steps = X.shape[1]\n",
    "    max_random_int = len(y) - n_steps\n",
    "    \n",
    "    y_true, y_pred = [], []\n",
    "    pred_accuracy, slices = [], []\n",
    "    \n",
    "    for i in range(n_preds):\n",
    "        if random == True: \n",
    "            position = np.random.randint(0, max_random_int)\n",
    "        else:\n",
    "            position = i \n",
    "            \n",
    "        y_hat = model.predict(X[position:position+1])[0][0]\n",
    "        y_pred.append(y_hat)\n",
    "        y_true.append(y[position])\n",
    "        y_current = y[position]\n",
    "        \n",
    "        if y.min() < 0:\n",
    "            c = 0 \n",
    "        else: \n",
    "            c = y[position-1]\n",
    "        \n",
    "        if ((y_hat > c) & (y_current > c)) or ((y_hat < c) & (y_current < c)): \n",
    "            acc = 1\n",
    "        else:\n",
    "            acc = 0 \n",
    "            \n",
    "        pred_accuracy.append(acc)\n",
    "        slices.append((list(y[position-n_steps : position+1]) + [y_hat], acc))\n",
    "    \n",
    "    if show_graph == True:\n",
    "        plt.rcParams['figure.dpi']=227\n",
    "        plt.style.use('seaborn-whitegrid')\n",
    "        plt.figure(figsize=(18,5))\n",
    "        \n",
    "        plt.bar(range(n_preds), y_true[:], width=.7, alpha=.6, color=lightblue, label=\"True\")\n",
    "        plt.bar(range(n_preds), y_pred[:], width=.7, alpha=.6, color=pinkyred, label=\"Predicted\")\n",
    "        \n",
    "        plt.axhline(0,color=black,lw=.8)\n",
    "        plt.legend(frameon=True, loc=1, borderpad=.6)\n",
    "        plt.title('Convolution Network: Daily Return Prediction for '+ticker.upper(), fontsize=20)\n",
    "        plt.show()\n",
    "    \n",
    "    print('MSE: ', mean_squared_error(y_true,y_pred))\n",
    "    print('Accuracy: {}%'.format(round((sum(pred_accuracy)/len(pred_accuracy))*100, 2)))\n",
    "    return slices, np.array(y_true), np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359545c1-3f5b-4577-9275-7e45847defff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, y_true, y_pred = evaluation(X_test, y_test, model, random=False, n_preds=50, show_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed79c1-b0fa-4253-ad7a-f402b726fb06",
   "metadata": {},
   "source": [
    "## Combined Stock Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33fddf1-9fcc-40ff-806d-9e1d0d7a49bf",
   "metadata": {},
   "source": [
    "#### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a468849-435e-4ea5-9861-ce7809275e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stocks = pd.concat(stocks,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5783116-04e7-4bee-ab82-eff3dbecc840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(dataframe, scale=(0,1)):\n",
    "    # Scale Features to [0-1]\n",
    "    columns = dataframe.columns \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.feature_range = scale \n",
    "    return pd.DataFrame(scaler.fit_transform(dataframe), columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b74306-2381-4a8b-bb70-4caf8cb70135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(features, target, n_steps, split=True, ratio=0.8):\n",
    "    X, y = [],[]\n",
    "    \n",
    "    for i in range(len(features)):\n",
    "        end_index = i + n_steps\n",
    "        if end_index > len(features): \n",
    "            break\n",
    "        seq_x, seq_y = features[i:end_index], target[end_index-1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    if split==True:\n",
    "        X_train = np.array(X[:round(len(X)*ratio)])\n",
    "        y_train = np.array(y[:round(len(X)*ratio)])\n",
    "        X_test = np.array(X[round(len(X)*ratio):])\n",
    "        y_test = np.array(y[round(len(X)*ratio):])\n",
    "        return X_train, y_train, X_test, y_test\n",
    "    else: \n",
    "        return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f74e86-cfa8-4ea5-8977-c26f9ee262b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scaled = scale(all_stocks, scale=(0,1))\n",
    "\n",
    "n_steps = 21\n",
    "X_train, y_train, X_test, y_test = split_sequences(\n",
    "                                    all_scaled.to_numpy()[:-1], \n",
    "                                    all_stocks['Return'].shift(-1).to_numpy()[:-1], n_steps, split=True, ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cb89da-4ac5-45f7-8573-08cd196ffbf4",
   "metadata": {},
   "source": [
    "### Model Loss\n",
    "# NAN ISSUE = UPDATE STOCK SELECTION AND CLEAR THE NULL VALUES FROM IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f564ca-1b58-4b73-a11f-16b0bb925132",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "n_steps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=500, kernel_size=10, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=10))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d513b2-8423-40b7-aeef-1aa9181b3f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=25, verbose=0, validation_data=[X_test, y_test], use_multiprocessing=True)\n",
    "\n",
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "plt.plot(model.history.history['loss'], label='Loss')\n",
    "plt.plot(model.history.history['val_loss'], label='Value Loss')\n",
    "\n",
    "plt.legend(frameon=True, loc=1, borderpad=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41034106-07d2-4bca-b63d-98c224a73bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, y_true, y_pred = evaluation(\n",
    "                        X_test, y_test, model, random=True, n_preds=100, show_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442700e9-d284-4372-a1b7-3ae829f415e4",
   "metadata": {},
   "source": [
    "## Bayesian Optimizaion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc720962-8836-4fea-8cad-256c9df2a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_model(d1, d2, filters, pool, kernel):\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    d1, d2 = int(d1), int(d2)\n",
    "    filters, kernel, pool = int(filters), int(kernel), int(pool)\n",
    "    \n",
    "    n_steps = X_train.shape[1]\n",
    "    n_features = X_train.shape[2]\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=filters, kernel_size=kernel, activation='relu', input_shape=(n_steps, n_features)))\n",
    "    model.add(MaxPooling1D(pool_size=pool))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(d1, activation='relu'))\n",
    "    model.add(Dense(d2, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "    model.fit(X_train, y_train, epochs=4, verbose=0, validation_data=[X_test,y_test], use_multiprocessing=True)\n",
    "    \n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b144d8db-b34e-4422-908e-15f1a21994e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_optimization():\n",
    "    \n",
    "    pbounds = {\n",
    "        'filters': (1,10),\n",
    "        'd1': (16,250),\n",
    "        'd2': (10,40),\n",
    "        'kernel': (2,10),\n",
    "        'pool': (2,10)\n",
    "    }\n",
    "    optimizer = BayesianOptimization(\n",
    "                f = bayesian_model, \n",
    "                pbounds = pbounds,\n",
    "                random_state = 1, \n",
    "                verbose = 2 \n",
    "    )\n",
    "    optimizer.maximize(init_points=5, n_iter=5)\n",
    "    print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7bceff-d591-4fe6-94be-63c8198e36a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 21\n",
    "scaled_ticker = scale(stocks[ticker.lower()], scale = (0,1))\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_sequences(\n",
    "            scaled_ticker.to_numpy()[:-1],\n",
    "            stocks[ticker.lower()].Return.shift(-1).to_numpy()[:-1],\n",
    "            n_steps,\n",
    "            split=True,\n",
    "            ratio=0.8\n",
    ")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f3b05-eb81-4282-b70e-ccb3b10ec8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_optimization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0bd086-d8a2-4524-bec8-80428bdd2d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=9, kernel_size=5, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=9))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad73fc-3f56-4d52-9ffe-1ffb664060c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=100, verbose=0, validation_data=[X_test, y_test], use_multiprocessing=True)\n",
    "\n",
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "plt.plot(model.history.history['loss'], label='Loss')\n",
    "plt.plot(model.history.history['val_loss'], label=\"Value Loss\")\n",
    "\n",
    "plt.title(\"Convolution Network: Training Process for \"+ticker.upper(), fontsize=20)\n",
    "plt.legend(frameon=True, loc=1, borderpad=.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb54ff4-9612-4859-8b95-ac9ff2b8095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, y_true, y_pred = evaluation(X_test, y_test, model, random=True, n_preds=100, show_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6700237-ecb4-4501-8752-1a4500e2b655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
